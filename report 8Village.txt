Since last month I and my team have been researching about machine learning for text analysis which includes sentiment analysis, topic classification, intent classification and named entity recognition. This research is more like a challenge for us due to our knowledge and experience regarding ML that close to zero, but we need to deliver MVP as soon as possible (3 weeks or so). Fortunately, even though it's not perfect, somehow we manage to build an API that fulfill 2 out of 4 features target that I mention previously which are topic classification and intent classification. In this article I would like to share our experience on how someone new to machine learning can build fully functioning text classifier using it.
The first thing that we do to start this project is deciding which feature is the easiest to work on. We understand that basicaly the required feature only involve 2 problem which are classification and named entity recognition. After 30 minutes discussion and google searching, we decide to work on classifier problem first because in need less data to train and the technique required to implement classifier is much simpler. Not to mention most named entity recognition example that we found was language dependen which means that it can only recognise named entity if the input text is in certain language commonly spoken internationally such as english or spain. This is so unfortunante since our input would be in Bahasa Indonesia and most of them in informal form. If you are wondering what our data looks like, here it is:
<Data question without label>
I assume now you understand our pain, if we decide to work on named entity recognition firt. 
Since we got the data from an online agriculture forum, most of our data contains informal word, even some sentences contain no formal word at all. This became a problem because all named entity recognition technique that we found need full list of words that might appear in the input and it is imposible for us to list down all the informal word in the internet. Why?. Well, you know how unpredictable people can be when they try to shorten the words they type. For example the word "untuk", most people will shorten it into "utk" or "u/", but i found unusual way to shorten it in the data such as "unt" or just "u". Even if somehow we, magically, can formalize the data, it still gonna be dificult for us to build NER for Bahasa Indonesia due to difference in gramatical rules with example we found (English andd Spain). We need to formulate gramatical rules for Bahasa Indonesia which gonna takes a lot of time and the technique required is complex. Therefore, we decided to work on classifier first because it is language independent and preprocessing step (formalization) is optional.
After we decided to work on classifier first, we need to decide what approach we will use to build it, supervised or unsupervised ML. If we implement the supervised approach, we need to manually give label to hundreds data for training purpose which gonna be tiring and boring, but if we implement the unsupervised one, there was several critical knowledge gaps that we can't cover in just 3 weeks especially regarding the design of training process. Therefore, even though we need to manually give label to our data, we chose to go with the supervised one, understanding the time constrain we had.