Since last month I and my team have been researching about machine learning for text analysis which includes sentiment analysis, topic classification, intent classification and named entity recognition. This research is more like a challenge for us due to our knowledge and experience regarding ML that close to zero, but we need to deliver MVP as soon as possible (3 weeks or so). Fortunately, even though it's not perfect, somehow we manage to build an API that fulfill 2 out of 4 features target that I mention previously which are topic classification and intent classification. In this article I would like to share our experience on how someone new to machine learning can build fully functioning text classifier.
The first thing that we do to start this project is deciding which feature is the easiest to work on. We understand that the required feature can be categorized into 2 problem which are classification and named entity recognition. After 30 minutes discussion and google searching, we decide to work on classifier problem first because in need less data to train and the technique required to implement classifier is much simpler. Not to mention most named entity recognition example that we found was language dependen which means that it can only recognise named entity if the input text is in certain language commonly spoken internationally such as english or spain. This is so unfortunante since our input would be in Bahasa Indonesia and most of them in informal form. If you are wondering what our data looks like, here it is:
<Data question without label>
I assume now you understand our pain, if we decide to work on named entity recognition first. 
Since we got the data from an online agriculture forum, most of our data contains informal word, even some sentences contain no formal word at all. This became a problem because all named entity recognition technique that we found need full list of words that might appear in the input and it is imposible for us to list down all the informal word in the internet. Why?. Well, you know how unpredictable people can be when they try to shorten the words they type. For example the word "untuk", most people will shorten it into "utk" or "u/", but i found unusual way to shorten it in the data such as "unt" or just "u". Even if somehow we, magically, can formalize the data, it still gonna be dificult for us to build NER for Bahasa Indonesia due to difference in gramatical rules with the example we found (English andd Spain). We need to formulate gramatical rules for Bahasa Indonesia which gonna takes a lot of time and the technique required is complex. Therefore, we decided to work on classifier first because it is language independent and preprocessing step (formalization) is optional.
After we decided to work on classifier first, we need to decide what approach we will use to build it, supervised or unsupervised ML. If we implement the supervised approach, we need to manually give label to hundreds of data for training purpose which gonna be tiring and boring, but if we implement the unsupervised one, there was several critical knowledge gaps that we can't cover in just 3 weeks especially regarding the design of training process. Therefore, even though we need to manually give label to our data, we chose to go with the supervised one.
At this point, we have several algorithm that we could choose to implement supervised learning which are naive bayesian, LDA, SVM and Neural Network. But before we choose the algorithm, we need to find a method to translate words into an array since all algorithm that I mention previously need input in form of array or at least numbers. There is 2 options that we had to do that, by using one hot encoded bag of words (bow) [https://en.wikipedia.org/wiki/Bag-of-words_model] or word2vec(CBOW)[https://en.wikipedia.org/wiki/Word2vec]. If we had more times, we definitely would choose word2vec to embbed the input since the size of array would be significantly smaller compared to BOW, but we had limited time and to implement word2vec we need to use Java (deeplearn4j[https://deeplearning4j.org/word2vec.html]) or Python(gensim[https://radimrehurek.com/gensim/models/word2vec.html]) which no one between us had any experience making an API using these language. Actually, it is possible for us to create the classifier by using Python but problem will occur in the process of making an API out of it, especially in the deployment process. To deploy Python in the live server, there is several configuration[https://www.analyticsvidhya.com/blog/2017/09/machine-learning-models-as-apis-using-flask/] that needs to be done and we don't have the courage to play around with our company server since everyone else is also using it for other project. So for the sake of familiarity we decide to use BOW which we manage to find a node package to implement it called mimir [https://www.npmjs.com/package/mimir].
Some of you might think that we do a lot of simplification in this project because we want to take an easy way, but the truth is, we just want to explore more about ML technique to ensure optimize the MVP. We need to understand that there are a lot of ML technique out there and each technique can be combined depending on resources and data set provided. So, basically in this project we spent most of our time by trying and evaluating any ML technique that we can think of under 3 criterias which are:
1. Training Time
2. Convergence Error
3. Classifier Accuracy
For this trial and error process we randomly picked 100 (80 training data + 20 test data) out of 2000+ data we provided and give 4 possible label to each data to represent intent which are question, advice, promotion and others. There are 2 algorithm out of 4 options that we actually try and evaluate which are Naive Bayesian (natural[https://www.npmjs.com/package/natural])and Neural Network (BrainJS[https://github.com/BrainJS/brain.js]). Eventhough LDA has principal difference[https://www.quora.com/Classification-machine-learning-What-are-the-main-differences-between-the-LDA-Linear-Discriminant-Analysis-and-Naive-Bayes-classifiers] with Naive Bayessian (NB), but since both algorithm using the same approach which is words probability, we conclude that the performance would be similiar with NB with only slight difference in accuracy. SVM is unique technique that actually more suitable for small data like ours, unfortunately SVM is not suitable for multiclass classifier problem [https://www.quora.com/For-what-kind-of-classification-problems-is-SVM-a-bad-approach] due to its nature that only capable to separate 2 classes (binary classification). Even though we found some intuition [https://stats.stackexchange.com/questions/21465/best-way-to-perform-multiclass-svm] on how using svm for multiclass classification, it makes the algorithm more complex and lose its comparative advantage over neural network which is its simplicity. So instead of try to use SVM, we use Neural Network and evaluate its performance.
After finishing training and evaluation process, we found out that bayessian take less time (20 minutes) and resource to train compared with NN (30 minutes) but unfortunately in term of accuracy NN perform better with approximately 71% accuracy compared to NB with less than 60% accuracy. The error most likely happen when the data should be classified as promotion, but both algorithm classify such data as question or advice. This is happen because improportional label in our training data. In our training data, there is only small number of data that manually classified as promotion while majority of them are classified into question and advice. To improve such condition, we need to increase more data that could be classified into promotion, but unfortunately in the 2000+ provided data there is still small number of promotion data, so for now we decide to ignore this solution and conclude that neural networ is the most suitabe algorithm for our problem. 
Theoritically, for bigger data, NN accuracy will improve more significantly compared to NB that will only slightly increase its accuracy. To prove that theory, we repeat the NN training process by using more data(250 training data and 50 test data). Unfortunately, somehow the training process takes unexpectedly 2 days to finish. At this moment there is 2 possible reason that the training proses takes significantly more time than the previous one. The first possibility is that, indeed it is imposible to use javascript to train such a big data since javascript only run in single thread cpu. Our last options would be to change our programming language to Python, but first we try to find alternative solution due to previously discussed problem if we use Python to create the API. Therefore, we decide to look for node package or library that enabling our training process to run on gpu which significantly faster than cpu. But, before we finish searching for gpu javascript library we decide to try to change our machine that run the training process. We suspected that the problem is in the machine hardware spec since we run the training in core i5 machine. Therefore we try to run our training process in other machine with core i7 processor, and it works. The training process only takes less than an hour to finish and we discover that the accuracy of our model increase to around 75%. 
An hour training process is not that bad but we have 2000+ data that need to be used in training process so we need to find a way to make the training process faster and one of the solution is by reducing BOW matrix. As we know, BOW will create a list of every word found in the training text. More words, bigger matrix size. Therefore, we tried to reduce the word count by using stopwords removal and stemming before creating dictionary(preprocessing). We first remove stopwords such as "yang", "di", "dari", "ke" etc because we believe that stopwords can be found in any sentence thus make it irrelevant to descriminate based on it. Because it's gonna takes time if we list down all stopwords in Bahasa Indonesia, we used nalapa [https://www.npmjs.com/package/nalapa] to determine whether a word is a stopwords or not and remove all stopwords found. After that, we stem the remaining words by removing prefix and suffix, so words such as "mempunyai", "dipunyai" and "punyaku" will only count as 1 word ("punya") instead of 4.